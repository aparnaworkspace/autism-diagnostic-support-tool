# **Apple-Health Inspired Streamlit App | XGBoost Model | SHAP Explainability | Full ML Pipeline**

A modern, end-to-end machine learning system that predicts Autism Spectrum Disorder (ASD) risk using the AQ-10 screening questionnaire, paired with transparent SHAP explanations, a clinical-style UI, and a clean PDF report generator.

Designed for learning, research demonstration, and portfolio showcasing â€” not for clinical diagnosis.

## â­ 1. Problem Statement

Early detection of Autism is essential for timely interventions, yet millions remain undiagnosed due to:

limited access to clinical screening

low awareness

long hospital wait-times

stigma and fear of assessment

This project builds an interactive ML-powered support tool that makes ASD risk assessment accessible, explainable, and easy to understand using a validated 10-question AQ-10 screening dataset.

## â­ 2. Why Autism Detection Matters

ASD affects 1 in 100 individuals globally.

Early detection improves language, learning, and social outcomes.

Digital tools help bridge the gap for low-resource clinical settings.

Machine learning can assist, but should never replace professional evaluation.


This project explores how ML + Explainability can enhance early screening systems.

## â­ 3. Dataset Description

Source:

Autism Screening Adults & Children Dataset (UCI / Kaggle Variants)

Contains:

AQ-10 responses (10 binary items)

Demographics: age, gender, ethnicity, country

Jaundice, family relations, â€œused app beforeâ€

Target column: Class/ASD â†’ renamed to class_asd

Size: ~700 rows

Type: Questionnaire-based classification

#### ğŸ“Œ Note: This dataset is small, simple, and diagnostic by design â€” which explains the high model performance.

## â­ 4. Project Pipeline (ML Workflow)


    A[Raw Data] --> B[Data Cleaning]
    B --> C[Feature Engineering]
    C --> D[Label Encoding]
    D --> E[Train-Test Split]
    E --> F[XGBoost Training]
    F --> G[Model Evaluation]
    G --> H[SHAP Explainability]
    H --> I[Streamlit App + PDF Report]
    I --> J[Deployment]

## â­ 5. System Architecture Diagram


    UI[Streamlit UI] --> API
    API[Prediction Engine] --> Model[XGBoost Model]
    API --> Scaler[StandardScaler]
    API --> Encoders[Label Encoders]
    Model --> SHAP[TreeExplainer]
    SHAP --> UI
    API --> Report[PDF Generator]

## â­ 6. Screenshot Previews

### ğŸ“± Home / Prediction Dashboard

<img width="1634" height="920" alt="Screenshot 2025-11-26 at 8 20 56â€¯AM" src="https://github.com/user-attachments/assets/800e538c-3cc8-4fc7-9d24-d9f603f1f5bf" />

<img width="1643" height="919" alt="Screenshot 2025-11-26 at 8 21 40â€¯AM" src="https://github.com/user-attachments/assets/1a3d1442-a1ee-4240-b6f4-f9f10d8154f3" />



### ğŸ“ PDF Report

<img width="701" height="546" alt="Screenshot 2025-11-26 at 8 23 44â€¯AM" src="https://github.com/user-attachments/assets/58bfa026-1a83-4a40-a868-3d22d82df919" />


## ğŸ” SHAP Local Explanation (Per-Patient)

This section shows **why the XGBoost model predicted ASD Positive/Negative** for a specific patient input.  
SHAP assigns each feature a positive (pushes toward ASD+) or negative (pushes toward ASDâˆ’) contribution.

### ğŸ“Œ Example Local SHAP Output
| Feature        | SHAP Value |
|----------------|------------|
| a9_score       | -1.2110    |
| a6_score       | -1.0042    |
| a5_score       | -0.8661    |
| a7_score       | -0.8091    |
| a3_score       | -0.7645    |
| a4_score       | -0.7368    |

### ğŸ” Interpretation  
- **Negative SHAP values** â†’ Feature pushes prediction toward *ASD Negative*  
- **Positive SHAP values** â†’ Feature pushes prediction toward *ASD Positive*  
- Higher absolute magnitude = **stronger impact**

This improves transparency and trust by showing *why* the model predicted what it did for each patient.


## â­ 7. Model Comparison Table


| Model               | Accuracy | F1 Score | Recall | AUC    |
|---------------------|----------|----------|--------|--------|
| Logistic Regression | **1.00** | **1.00** | **1.00** | 0.99 |
| Random Forest       | 0.94     | 0.89     | 0.84   | 0.996  |
| **XGBoost (Chosen)**| **0.986** | **0.974** | **0.974** | **0.9995** |
| Neural Network      | **1.00** | **1.00** | **1.00** | **1.00** |


## â­ 8. Model Stack

### Core Model

XGBoost Classifier

Tuned for small structured datasets

Supports Tree SHAP (fast, reliable)

### Explainability

SHAP TreeExplainer

Local + global attribution

Top 6 most influential features shown

## â­ 9. SHAP Example Images

### ğŸ“Œ Sample Local SHAP Bar Plot

<img width="800" height="1100" alt="shap_bar" src="https://github.com/user-attachments/assets/ac6114ae-60d1-4d10-b6c4-d5da2b87094f" />



### ğŸ“Œ SHAP Beeswarm (global)

<img width="800" height="910" alt="shap_beeswarm" src="https://github.com/user-attachments/assets/26891602-a186-40bf-bb43-1137f8649b3a" />



### ğŸ“Œ SHAP Waterfall Example

<img width="800" height="650" alt="shap_waterfall_sample_0" src="https://github.com/user-attachments/assets/073525b8-b967-4e00-818d-c55287b47071" />




## â­ 10. PDF Report Example

The app generates a clinical-style PDF including:

Prediction

Probability

AQ-10 Score

Risk Level

Recommendation

Top SHAP Features

<img width="1419" height="1092" alt="image" src="https://github.com/user-attachments/assets/7084f0a2-be79-424e-9e7d-dab4c60da130" />


## â­ 11. System Design Overview

### Backend

Model inference pipeline

Preprocessing (label encoders + scaler)

Age group derived feature

SHAP explanation engine

### Frontend

Apple HealthInspired UI

Glassmorphism cards

Real-time probability ring

### PDF generation

Storage

/models/ for artifacts

/reports/ for visual outputs

## â­ 12. How to Run Locally

1. Clone the repo
   
git clone https://github.com/aparnaworkspace/autism-diagnostic-support-tool
cd autism-diagnostic-support-tool

3. Create virtual environment

python3 -m venv venv
source venv/bin/activate

5. Install dependencies
   
pip install -r requirements.txt

7. Run Streamlit App
   
streamlit run app/streamlit_app.py

## â­ 13. Features Screenshot Section

Include images for:

Input form

Prediction card

SHAP charts

Risk level card

DF button

## â­ 14. Clinical Disclaimer

âš ï¸ This tool is NOT a clinical diagnostic system.

It is a portfolio project built for learning, experimentation, and demonstrating ML/SHAP explainability concepts.

Autism assessment requires:

clinical interviews

behavioural observation

developmental history

genetic & neurological assessment

## â­ 15. Folder Structure

autism-diagnostic-support-tool/

â”‚
â”œâ”€â”€ app/

â”‚   â””â”€â”€ streamlit_app.py

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ raw/

â”‚   â””â”€â”€ processed/

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ best_model.pkl

â”‚   â”œâ”€â”€ scaler.pkl

â”‚   â”œâ”€â”€ label_encoders.pkl

â”‚   â””â”€â”€ shap_explainer_and_values.pkl

â”œâ”€â”€ notebooks/

â”‚   â”œâ”€â”€ 01_EDA.ipynb

â”‚   â”œâ”€â”€ 02_Feature_Engineering.ipynb

â”‚   â””â”€â”€ 03_Model_Training.ipynb

â”œâ”€â”€ reports/

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ preprocess.py

â”‚   â”œâ”€â”€ train_model.py

â”‚   â”œâ”€â”€ risk_scoring.py

â”‚   â””â”€â”€ explainability.py

â””â”€â”€ README.md

## â­ 16. XGBoost Model Card

Model: XGBoostClassifier

Task: Binary classification (ASD / non-ASD)

Training data: AQ-10 questionnaire

Features: 19

Explainability: SHAP TreeExplainer

Intended use: Educational screening insights

Not intended for: Professional diagnosis

#### Strengths:

Highly separable dataset

Fast inference

Strong performance

Built-in explainability

#### Risks:

Overconfidence due to small dataset

Dataset biases may carry forward

## â­ 17. Limitations

### Data-related

Dataset is very small (< 800 samples)

Data is questionnaire-based, not multi-modal

AQ-10 questions are diagnostic, causing high separability

Labels may not represent real clinical outcomes

### Model-related

Cannot generalize to real-world populations

### Does not use:

behavioural observation

functional MRI

language patterns

genetics

App-related

Intended for education & research showcase only

## â­ 18. What I Learned

End-to-end ML pipeline design

XGBoost tuning

SHAP explainability (TreeExplainer)

Streamlit UI development

PDF report generation

Data engineering + encoding pipelines

ML ethics & model cards

GitHub project structuring

Deployment workflow

## â­ Final Notes

This project demonstrates:

âœ” Full ML pipeline
âœ” Modern, premium UI
âœ” Model explainability
âœ” Deployment-ready architecture
âœ” Excellent GitHub presentation
